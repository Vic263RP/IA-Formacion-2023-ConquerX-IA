{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Capa_densa:\n",
    "    # n_features y n_neuronas nos indica dimendión de la capa\n",
    "    def __init__(self, n_features, n_neuronas):\n",
    "        self.weights = 0.01*np.random.rand(n_features, n_neuronas)\n",
    "        self.bias = np.zeros((1, n_neuronas))\n",
    "\n",
    "    # Funciones de activación: ReLU, sigmoid\n",
    "    def relu(self, inputs):\n",
    "        # outputs = []\n",
    "        # for i in inputs:\n",
    "        #     if i > 0:\n",
    "        #         outputs.append(i)\n",
    "        #     else:\n",
    "        #         outputs.append(0)\n",
    "        return np.maximum(0, inputs)\n",
    "\n",
    "    def sigmoid(self, inputs): #Clasificación binaria y clasificación multietiqueta\n",
    "        \n",
    "        return 1 / (1 + np.exp(np.negative(inputs)))\n",
    "    \n",
    "    def softmax(self, inputs): # Clasificación clasificación multiclase etiquetas excluyentes\n",
    "        \n",
    "        return np.exp(inputs) / np.exp(inputs).sum(axis = 1, keepdims = True)\n",
    "    \n",
    "    def catecorical_crossentropy(truth, pred):\n",
    "        # Función clip. No queremos valores cercanos a 1 (log(1)=0) ni a 0 (log(0) No está definido)\n",
    "        y_pred_limite = np.clip(pred, 1e-7, 1-1e-7)\n",
    "        truth = pd.get_dummies(truth, dtype='int')\n",
    "        # np.log calcula el logaritmo de todas las predicciones y_pred_limite. Por lo que y_pred_limite.shape == np.log(y_pred_limite).shape\n",
    "        # Luego se multiplica por truth, que tampoco varía el shape inicial (con pd.get_dummies hemos creado un df de tantas columnas como clases queremos obtener)\n",
    "        # Por ultimo sumamos los valores de cada fila y obtenemos un aray de n filas y 1 columna con los loss de cada fila\n",
    "        loss = - np.sum(truth * np.log(y_pred_limite), axis = 1)\n",
    "        return loss\n",
    "\n",
    "        \n",
    "\n",
    "    def loss_fn(self, truth, pred, loss='catCrossEntropy'):\n",
    "        if loss == 'catCrossEntropy':\n",
    "            batch_loss = catecorical_crossentropy(truth, pred)\n",
    "            mean_loss = np.mean(batch_loss)\n",
    "\n",
    "            return mean_loss\n",
    "\n",
    "    def forward(self, inputs, activation = 'relu'):\n",
    "        self.prediction = np.dot(inputs, self.weights) + self.bias\n",
    "        if activation == 'relu':\n",
    "            self.prediction = self.relu(self.prediction)\n",
    "        if activation == 'sigmoid':\n",
    "            self.prediction = self.sigmoid(self.prediction)\n",
    "        if activation == 'softmax':\n",
    "            self.prediction = self.softmax(self.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'cat': [0,1,1,1,0,0,0,1,0,0,1,1,1,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56323187, 0.43676813],\n",
       "       [0.83047802, 0.16952198],\n",
       "       [0.18238955, 0.81761045],\n",
       "       [0.8495234 , 0.1504766 ],\n",
       "       [0.52745757, 0.47254243],\n",
       "       [0.3789084 , 0.6210916 ],\n",
       "       [0.68486119, 0.31513881],\n",
       "       [0.38052907, 0.61947093],\n",
       "       [0.86456451, 0.13543549],\n",
       "       [0.30427285, 0.69572715],\n",
       "       [0.23725568, 0.76274432],\n",
       "       [0.16865026, 0.83134974],\n",
       "       [0.35297906, 0.64702094],\n",
       "       [0.69778516, 0.30221484]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth = pd.get_dummies([0,1,1,1,0,0,0,1,0,0,1,1,1,0], dtype='int')\n",
    "y_pred = np.random.rand(14)\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred[1] = 1-y_pred[0]\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -0.574064\n",
       "1    -1.774773\n",
       "2    -0.201369\n",
       "3    -1.893948\n",
       "4    -0.639687\n",
       "5    -0.970461\n",
       "6    -0.378539\n",
       "7    -0.478890\n",
       "8    -0.145529\n",
       "9    -1.189830\n",
       "10   -0.270832\n",
       "11   -0.184705\n",
       "12   -0.435377\n",
       "13   -0.359844\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(truth * np.log(y_pred), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ConquerIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
